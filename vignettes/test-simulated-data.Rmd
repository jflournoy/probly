---
title: "Test Simulated Data"
author: "John Flournoy"
date: "`r Sys.Date()`"
output: 
  bookdown::html_document2:
    toc: yes
    toc_depth: 2
    number_sections: FALSE
pkgdown:
  as_is: true
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: "/home/jflournoy/Rlibs/probly/bib/dissertation.bib"
csl: "/home/jflournoy/Rlibs/probly/bib/apa-old-doi-prefix.csl"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  echo=F,message=F,warning=F,error=F
)
if(require(pkgdown, quietly = T, warn.conflicts = F) && pkgdown::in_pkgdown()){
    knitr::opts_chunk$set(eval = T)
    vignette_message <- ''
} else {
    knitr::opts_chunk$set(eval = F, echo = T) #Do not build vignette but provide text and code
    vignette_message <- "
------

This vignette is not evaluated, but is included to provide 
    text describing the model and code as example. The compiled document can be viewed
    [on the `probly` package website](https://jflournoy.github.io/probly/).

------    
"
}

knitr::read_chunk(system.file('r_aux', 'load_data_for_sim.R', package = 'probly'))
knitr::read_chunk(system.file('r_aux', 'test_simulation_2l_nob.R', package = 'probly'))
knitr::read_chunk(system.file('batchtools', 'run_many_simulations.R', package = 'probly'))
data_dir <- '/data/jflournoy/split/probly'
save_out_dir <- '~/code_new/social-motives-rl-writeup/rda/'
if(!dir.exists(save_out_dir)){
    dir.create(save_out_dir)
}
```

`r vignette_message`

**Aim 1a:** Does framing reinforcement learning with (mate-seeking and status) motivational contexts sensitize the learner and potentiate learning?

My approach to answering this question is to model how learning occurs in each of the three motive contexts and examine differences in how learning occurs.

# A model for reinforcement learning

In the context of this task, where the relation between the optimal response and the stimulus is constant, a simple model of the degree of learning could rely on a simple proportion of optimal responses $P_{ok}$ for each condition $k$.
The test of the hypothesis of the effect of framing would then be the difference between conditions in $P_o$. 
This simple model sacrifice precision for simplicity, and so I will be modeling the data using a reinforcement learning model with several parameters that can account for deviations from a strict Rescorla-Wagner (RW) process.
This increases the number of possible comparisons I am able to make between conditions, which may generate useful information about how motive-domain framing affects the learning process (as modeled, of course), but which also increases the complexity of patterns between conditions and parameters that must be interpreted.
It will be helpful to keep in mind that the framing can only be said to potentiate learning if, regardless of its affect on any model parameters, it does not result in higher proportions of optimal responding.

In this section, I simulate data as expected under the Rescorla-Wagner model implemented by @ahn2017 in their go-no-go model 2. 
Their original model handles binary decisions (button-press or no button-press) in response to four different cues. 
However, the form of the learning algorithm is generalizable to other binary choices in response to cues. 
In the case of the Social Probabilistic Learning Task (SPLT), participants are presented with a face (the cue), and must decide to press the left key or the right key. 
They are rewarded probabilistically such that for each cue, one or the other of the response options has an 80% chance of providing reinforcement. 
The go-no-go models used by @ahn2017 were derived from work by @guitart-masip2012. 
Their most flexible reinforcement learning model generates the probability of an action for each trial via N parameters: the learning rate, $\epsilon$, the effective size of reinforcement, $\rho$, a static bias parameter, $b$, an irreducible noise parameter, $\xi$, and a Pavlovian learning parameter, $\pi$.
In the SPLT, trial feedback does not vary by valence (responses result in reward, or no reward, but never punishment), so I use the model that does not include this Pavlovian component. 

# Reinforcement learning model for the SPLT

The model for an individual $j$'s probability of pressing the right arrow key on trial $t$ given that stimulus $s_{t}$ is presented, $P(a_{\rightarrow t} | s_{t})_{t}$, is determined by a logistic transformation of the action weight for pressing the right arrow key minus the action weight for pressing the left arrow key. 
This probability is then adjusted by a noise parameter, $0 \leq\xi_{jk}\leq1$ for each participant $j$ in condition $k$.
The noise parameter modulates the degree to which responses are non-systematic. 
When $\xi$ is 1, $P_{it} = .5$, and because each individual has a unique noise parameter for each condition, I am able to account for participants who do not learn during the task, or in a particular condition.
The full equation is:

$$
P(a_{\rightarrow t} | s_{t})_{t} = 
\text{logit}^{-1}\big(W(a_{\rightarrow t}| s_{t}) - W(a_{\leftarrow t}| s_{t})\big)\cdot(1-\xi_{jk}) + \small\frac{\xi_{jk}}{2}.
$$

The action weight is determined by a Rescorla-Wagner (RW) updating equation and individual $j$'s bias parameter, $b_{jk}$, for that condition (which encodes a systematic preference for choosing the left or right response option).
In each condition, the same two words are displayed in the same position, so $b$ encodes a learning-independent preference for one particular word or position.
The equation for the action weight for each action on a particular trial is:

$$
W_{t}(a,s) = \left\{
                \begin{array}{ll}
                  Q_{t}(a, s) + b_{jk}, & \text{if } a=a_{\rightarrow} \\
                  Q_{t}(a, s), & \text{otherwise}
                \end{array}
              \right.
$$
Finally, the RW updating equation that encodes instrumental learning is governed by the individual's learning rate for that condition, $\epsilon_{jk}$, and a scaling parameter $\rho_{jk}$ governing the effective size of the possible rewards $r_t \in \{0, 1, 5\}$:

$$
Q_{t}(a_t, s_t) = Q_{t-1}(a_t, s_t) + \epsilon_{jk}\big(\rho_{jk}r_t - Q_{t-1}(a_t, s_t)\big)
$$

## Hierarchical Parameters

Each parameter ($\epsilon, \rho, b, \xi$) varies by condition $k \in 1:K$, and by participant $j \in 1:J$ nested in sample $m \in 1:M$. 
The structure of the hierarchical part of the model is the same for each parameter, so the following description for $\epsilon$ will serve as a description for all of the parameters.
For each individual $j$, $\beta_{\epsilon j}$ is a $K$-element row of coefficients for parameter $\epsilon$ for each condition:

$$
\beta_{\epsilon j} \sim \mathcal{N}(\delta_{\epsilon mm[j]}, \Sigma_{\epsilon})
$$
where $\delta_{\epsilon mm[j]}$ is a column of $K$ means for individual $j$'s sample $M$, as indexed in the vector $mm$, and $\Sigma_{\epsilon}$ is a $K\times K$ matrix of the covariance of individual coefficients between conditions.

Finally, across all $M$ samples, the means for each condition k are distributed such that: 

$$
\delta_{\epsilon k} \sim \mathcal{N}(\mu_{\epsilon k}, \sigma_\epsilon)
$$

where $\mu_{\epsilon k}$ is the population mean for parameter $\epsilon$ in condition $k$, and $\sigma$ is a slightly regularizing scale parameter for these means across all conditions and samples. The priors for these final parameters are:

$$
\mu_\epsilon \sim \mathcal{N}(0, 5)\\
\sigma_\epsilon \sim \text{exponential(1)}.
$$

# Simulating data

Before modeling the task data, I will confirm that this model can recover known parameters from simulated data.
I simulate data based on the structure of the sample data, using the same number of participants per sample (see the section on [descriptive statistics](descriptive-statistics.html), as well as precisely the same task structure. 
For this aim, it is important to be able to recover all $\mu_{\theta k}$ for $\theta \in \{\epsilon,\rho,b,\xi\}$ and $k \in \{1,2,3\}$, where 1 = Hungry/Thirsty, 2 = Popular/Unpopular, and 3 = Dating/Looking. Those parameters that account for idiosyncratic deviation from RW-expected behavior ($b,\xi$) will not vary by condition. Based on interactive simulation ([here](https://jflournoy.shinyapps.io/rw_model/)), reasonable parameter values for the control condition might be $\mu_\epsilon = -1.65$ and $\mu_\rho = -0.3$ [^1].

[^1]: Note that these are the _raw_ parameter values which are transformed such that $\epsilon^\prime \in [0,1]$ and $\rho^\prime \in [0,\infty)$. Similar to logistic regression, estimating the parameters on a scale the is not resticted improves estimation.

The [`probly`](http://github.com/jflournoy/probly) package contains functions that help generate sample- and individually-varying coefficients for parameters, as well as simulated data from task structure.


```{r load_data_for_sim}
```

```{r test_simulation_2l_nob}
```

One early indication that a model may not be well suited to a problem is that when generating from the prior distribution, datasets are produced that either do not adequately cover the range of reasonable values, or that cover ranges that are implausible [@gabry2017]. 
The simulated data do generally cover the range of the actual data when we look just at the proportion of optimal presses over time (Figure \@ref(fig:simdata), and importantly do not show implausible behavior (all mass around extreme values like 0, 1, or .5).

(ref:simdat) Simulated task data. This shows the the proportion of optimal presses across all participants for each trial. The best-fit line is a generalized additive model smooth and is only intended to give a rough sense of trends over trials. Each panel is one from 400 simulated data sets. The red line indicates random responding.

```{r simdata, fig.width=8, fig.height=5, fig.cap='(ref:simdatcoverage)'}
multi_plot <- probly::plot_splt_sim_behavior(
    splt_df = splt,
    press_right = list_of_pright_pred_mats)
nosmooth_multi_plot <- multi_plot
nosmooth_multi_plot$layers[[2]] <- NULL
nosmooth_multi_plot
```

(ref:simdatcoverage) Simulated task data. This shows the the proportion of optimal presses across all participants for each trial, collapsed over simulations. It's possible to see that trial-by-trial probability of choosing the optimal resonses, averaged across all participants, spans the full range of possible behavior (with the extreme exception that no simulation evinces all participants performing perfectly).

```{r simdatcoverage, fig.width=15, fig.height=12, fig.cap='(ref:simdat)'}
multiplot_by_sim <- multi_plot + 
    ggplot2::facet_wrap(~sim) + 
    ggplot2::theme(strip.background = element_blank(),
                   strip.text = element_blank())
multiplot_by_sim
```

(ref:priorplots) Priors, with $epsilon$ and $\xi$ on their transformed scales. Notice the very long tails for the individually varying $rho$ parameters (beta_rho). 

```{r priorplots, fig.width=3, fig.height=2, fig.cap='(ref:priorplots)'}
# rl_2l_nob_sim <- readRDS('/data/jflournoy/split/probly/splt_sim2_test_sims.RDS')
ggplot2::theme_set(ggplot2::theme_minimal())
true_mu_ep <- rstan::extract(rl_2l_nob_sim, pars = 'mu_delta_ep')[[1]]
true_mu_rho <- rstan::extract(rl_2l_nob_sim, pars = 'mu_delta_rho')[[1]]
true_mu_xi <- rstan::extract(rl_2l_nob_sim, pars = 'mu_delta_xi')[[1]]
true_beta_ep <- rstan::extract(rl_2l_nob_sim, pars = 'beta_ep_prm')[[1]]
true_beta_rho <- rstan::extract(rl_2l_nob_sim, pars = 'beta_rho_prm')[[1]]
true_beta_xi <- rstan::extract(rl_2l_nob_sim, pars = 'beta_xi_prm')[[1]]
true_tau_ep <- rstan::extract(rl_2l_nob_sim, pars = 'tau_ep')[[1]]
true_tau_xi <- rstan::extract(rl_2l_nob_sim, pars = 'tau_xi')[[1]]
true_tau_rho <- rstan::extract(rl_2l_nob_sim, pars = 'tau_rho')[[1]]
sample_pR_final <- rstan::extract(rl_2l_nob_sim, pars = 'pR_final')[[1]]

dimnames(true_mu_ep)[[3]] <- c('mu_ep_1', 'mu_ep_2', 'mu_ep_3')
dimnames(true_mu_rho)[[3]] <- c('mu_rho_1', 'mu_rho_2', 'mu_rho_3')
dimnames(true_mu_xi)[[3]] <- c('mu_xi_1', 'mu_xi_2', 'mu_xi_3')
dimnames(true_beta_ep)[[3]] <- c('beta_ep_1', 'beta_ep_2', 'beta_ep_3')
dimnames(true_beta_rho)[[3]] <- c('beta_rho_1', 'beta_rho_2', 'beta_rho_3')
dimnames(true_beta_xi)[[3]] <- c('beta_xi_1', 'beta_xi_2', 'beta_xi_3')
dimnames(true_tau_ep)[[2]] <- c('tau_ep_1', 'tau_ep_2', 'tau_ep_3')
dimnames(true_tau_xi)[[2]] <- c('tau_xi_1', 'tau_xi_2', 'tau_xi_3')
dimnames(true_tau_rho)[[2]] <- c('tau_rho_1', 'tau_rho_2', 'tau_rho_3')
dimnames(sample_pR_final)[[3]] <- paste0('cue_',1:6)

true_mu_ep_hist <- bayesplot::mcmc_hist(pnorm(true_mu_ep))
true_beta_ep_hist <- bayesplot::mcmc_hist(true_beta_ep, adjust = .5) + ggplot2::coord_cartesian(xlim = c(0,1))
true_mu_rho_hist <- bayesplot::mcmc_hist(true_mu_rho) + ggplot2::coord_cartesian(xlim = c(-5, 5))
true_beta_rho_hist <- bayesplot::mcmc_hist(log(true_beta_rho), adjust = 2) + ggplot2::coord_cartesian(xlim = c(-15, 15))
true_mu_xi_hist <- bayesplot::mcmc_hist(pnorm(true_mu_xi))
true_beta_xi_hist <- bayesplot::mcmc_hist(true_beta_xi, adjust = .05)
true_tau_ep_hist <- bayesplot::mcmc_hist((true_tau_ep), adjust = .05)
true_tau_xi_hist <- bayesplot::mcmc_hist((true_tau_xi), adjust = .05)
true_tau_rho_hist <- bayesplot::mcmc_hist((true_tau_rho), adjust = .05)
sample_pR_final_hist <- bayesplot::mcmc_hist((sample_pR_final), adjust = .05)

true_mu_ep_hist
true_beta_ep_hist
true_mu_rho_hist
true_beta_rho_hist
true_mu_xi_hist
true_beta_xi_hist
true_tau_ep_hist
true_tau_xi_hist
true_tau_rho_hist
sample_pR_final_hist
```

```{r fig.width=12,fig.height=12}
bayesplot::mcmc_pairs(data.frame(true_beta_rho_1 = as.numeric(log(true_beta_rho[,,1])), 
                                 true_beta_rho_2 = as.numeric(log(true_beta_rho[,,2])), 
                                 true_beta_rho_3 = as.numeric(log(true_beta_rho[,,3])), 
                                 true_beta_ep_1 = as.numeric(qnorm(true_beta_ep[,,1])),
                                 true_beta_ep_2 = as.numeric(qnorm(true_beta_ep[,,2])),
                                 true_beta_ep_3 = as.numeric(qnorm(true_beta_ep[,,3])),
                                 true_beta_xi_1 = as.numeric(qnorm(true_beta_xi[,,1])),
                                 true_beta_xi_2 = as.numeric(qnorm(true_beta_xi[,,2])),
                                 true_beta_xi_3 = as.numeric(qnorm(true_beta_xi[,,3])),
                                 pr_final_1 = as.numeric((sample_pR_final[,,1]))))
```

# Recovery of population parameters

The model as described above was fit to simulated data using RStan [version `r packageVersion('rstan')`; @standevelopmentteam2018], sampling from 4 chains with 1000 warmup iterations and 500 sampling iterations per chain. 
The posterior means for each parameter are compared to those that generated the simulated task behavior.
The plots in Figure \@ref(fig:musimfitplot) allow visual comparison of the fitted model posteriors for each parameter to the data-generating population means, as well as to the means of the data-generating parameters for each sample, and for each individual.
It is clear from these plots that the parameter estimates from this particular run capture the generating parameters, with two exceptions. 
First, the estimate of the population mean of the irrudicble noise parameter, $\xi$, for one condition did not capture the generating parameter. 
This may be because this parameter was intentionally set very low so that $\xi^\prime \approx 0$. 
The second instance occurs with the bias parameter for one condition. 
This may be acceptable because the parameters of interest safely capture the generating values, and this single condition bias parameter is not very far from the identity line. 
Additionally, it should be noted that the fitted model does capture the mean of generating $\delta_b$ and $\beta_b$ parameters for all conditions.

## One simulation

```{r onesimulation}
this_sim_plot <- probly::plot_splt_sim_behavior(
    splt_df = splt,
    press_right = list_of_pright_pred_mats[[test_sim_num]])
this_sim_plot$overall
```

```{r displots}
estimated_mu_ep <- rstan::extract(rl_2l_nob_simfit, pars = 'mu_delta_ep')[[1]]
estimated_mu_rho <- rstan::extract(rl_2l_nob_simfit, pars = 'mu_delta_rho')[[1]]
estimated_mu_xi <- rstan::extract(rl_2l_nob_simfit, pars = 'mu_delta_xi')[[1]]
estimated_beta_ep <- rstan::extract(rl_2l_nob_simfit, pars = 'beta_ep_prm')[[1]]
estimated_beta_rho <- rstan::extract(rl_2l_nob_simfit, pars = 'beta_rho_prm')[[1]]
estimated_beta_xi <- rstan::extract(rl_2l_nob_simfit, pars = 'beta_xi_prm')[[1]]
estimated_tau_ep <- rstan::extract(rl_2l_nob_simfit, pars = 'tau_ep')[[1]]
estimated_tau_unif_ep <- rstan::extract(rl_2l_nob_simfit, pars = 'tau_unif_ep')[[1]]
estimated_tau_xi <- rstan::extract(rl_2l_nob_simfit, pars = 'tau_xi')[[1]]
estimated_tau_rho <- rstan::extract(rl_2l_nob_simfit, pars = 'tau_rho')[[1]]
estimated_sample_pR_final <- rstan::extract(rl_2l_nob_simfit, pars = 'pR_final')[[1]]

dimnames(estimated_mu_ep)[[3]] <- c('mu_ep_1', 'mu_ep_2', 'mu_ep_3')
dimnames(estimated_mu_rho)[[3]] <- c('mu_rho_1', 'mu_rho_2', 'mu_rho_3')
dimnames(estimated_mu_xi)[[3]] <- c('mu_xi_1', 'mu_xi_2', 'mu_xi_3')
dimnames(estimated_beta_ep)[[3]] <- c('beta_ep_1', 'beta_ep_2', 'beta_ep_3')
dimnames(estimated_beta_rho)[[3]] <- c('beta_rho_1', 'beta_rho_2', 'beta_rho_3')
dimnames(estimated_beta_xi)[[3]] <- c('beta_xi_1', 'beta_xi_2', 'beta_xi_3')
dimnames(estimated_tau_ep)[[2]] <- c('tau_ep_1', 'tau_ep_2', 'tau_ep_3')
dimnames(estimated_tau_unif_ep)[[2]] <- c('tau_ep_1', 'tau_ep_2', 'tau_ep_3')
dimnames(estimated_tau_xi)[[2]] <- c('tau_xi_1', 'tau_xi_2', 'tau_xi_3')
dimnames(estimated_tau_rho)[[2]] <- c('tau_rho_1', 'tau_rho_2', 'tau_rho_3')
dimnames(estimated_sample_pR_final)[[3]] <- paste0('cue_',1:6)
```

## Learning rate ($\epsilon$)

```{r}
plot_mu_estimates_v_sims(estimated_samples = estimated_mu_ep[,1,], 
                         sim_params = true_mu_ep[test_sim_num,,], transform = 'pnorm')
plot_mu_estimates_v_sims(estimated_samples = estimated_tau_ep, 
                         sim_params = true_tau_ep[test_sim_num,], contrasted = F)
```

```{r}
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_ep[,,1], 
                           sim_params = true_beta_ep[test_sim_num,,1], 
                           title = expression(paste(beta[epsilon[1]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_ep[,,2], 
                           sim_params = true_beta_ep[test_sim_num,,2], 
                           title = expression(paste(beta[epsilon[2]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_ep[,,3], 
                           sim_params = true_beta_ep[test_sim_num,,3], 
                           title = expression(paste(beta[epsilon[3]])))
```

```{r showmanyiep, fig.width=8, fig.height=30}
i_idx <- sample(1:308, size = 40)
bayesplot::mcmc_hist_by_chain(qnorm(estimated_beta_ep[,i_idx,])) +
    ggplot2::coord_cartesian(xlim = c(-5,5)) +
    ggplot2::geom_vline(
        aes(xintercept = value), 
        data = data.frame(
            value = as.numeric(qnorm(true_beta_ep[test_sim_num,i_idx,])), 
            Parameter = rep(dimnames(true_beta_ep[test_sim_num,i_idx,])[[2]], each = length(i_idx)),
            Chain = rep(1:length(i_idx), 3)))
```

## Temperature ($\rho$)

```{r}
plot_mu_estimates_v_sims(estimated_samples = estimated_mu_rho[,1,], 
                         sim_params = true_mu_rho[test_sim_num,,])
plot_mu_estimates_v_sims(estimated_samples = estimated_tau_rho, 
                         sim_params = true_tau_rho[test_sim_num,], contrasted = F)
```

```{r}
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_rho[,,1], 
                           sim_params = true_beta_rho[test_sim_num,,1], 
                           title = expression(paste(beta[rho[1]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_rho[,,2], 
                           sim_params = true_beta_rho[test_sim_num,,2], 
                           title = expression(paste(beta[rho[2]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_rho[,,3], 
                           sim_params = true_beta_rho[test_sim_num,,3], 
                           title = expression(paste(beta[rho[3]])))
```

```{r showmanyirho, fig.width=8, fig.height=30}
i_idx <- sample(1:308, size = 40)
bayesplot::mcmc_hist_by_chain(log(estimated_beta_rho[,i_idx,])) +
    ggplot2::geom_vline(
        aes(xintercept = value), 
        data = data.frame(
            value = as.numeric(log(true_beta_rho[test_sim_num,i_idx,])), 
            Parameter = rep(dimnames(true_beta_rho[test_sim_num,i_idx,])[[2]], each = length(i_idx)),
            Chain = rep(1:length(i_idx), 3)))
```

## Noise ($\xi$)

```{r}
plot_mu_estimates_v_sims(estimated_samples = estimated_mu_xi[,1,], 
                         sim_params = true_mu_xi[test_sim_num,,], transform = 'pnorm')
plot_mu_estimates_v_sims(estimated_samples = estimated_tau_xi, 
                         sim_params = true_tau_xi[test_sim_num,], contrasted = F)
```

```{r}
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_xi[,,1], 
                           sim_params = true_beta_xi[test_sim_num,,1], 
                           title = expression(paste(beta[xi[1]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_xi[,,2], 
                           sim_params = true_beta_xi[test_sim_num,,2], 
                           title = expression(paste(beta[xi[2]])))
probly::plot_beta_estimates_v_sims(estimated_samples = estimated_beta_xi[,,3], 
                           sim_params = true_beta_xi[test_sim_num,,3], 
                           title = expression(paste(beta[xi[3]])))
```

```{r showmanyixi, fig.width=8, fig.height=30}
i_idx <- sample(1:308, size = 40)
bayesplot::mcmc_hist_by_chain(qnorm(estimated_beta_xi[,i_idx,])) +
    ggplot2::geom_vline(
        aes(xintercept = value), 
        data = data.frame(
            value = as.numeric(qnorm(true_beta_xi[test_sim_num,i_idx,])), 
            Parameter = rep(dimnames(true_beta_xi[test_sim_num,i_idx,])[[2]], each = length(i_idx)),
            Chain = rep(1:length(i_idx), 3)))
```

## Final probability of pressing left or right

```{r pRfinalplot, fig.width=8, fig.height=5}
pR_final_plots <- lapply(1:6, function(i){
  probly::plot_beta_estimates_v_sims(estimated_samples = estimated_sample_pR_final[,,i], 
                           sim_params = sample_pR_final[test_sim_num,,i], 
                           title = paste0('Stimulus: ', i))
})
pR_final_plots[['nrow']] <- 2
do.call(gridExtra::grid.arrange, pR_final_plots)
```

# Fitting to many simulations

After generating 100 simulated data sets, models were fit to each. The empirical cummulative density function was composed to each posterior distribution for each parameter, and the generating value (from the simulation) was located within that density. If the posterior is a reasonable estimate of the generating parameter, then the generating parameter should be a random draw from that posterior. As such, the distribution of the "_p_-value" of the generating parameters (in relation to the posteriors) should be uniform. Below you are demonstrations of adherence to or departure from this.

```{r run_many_simulations, eval = F, echo = T}
```

```{r}
ecdf_files <- dir(file.path(data_dir), pattern = '*ecdf*', full.names = T)

mu_ecdfrez_df <- do.call(
    rbind,
    lapply(ecdf_files, function(filename){
        some_ecdfs <- readRDS(filename)
        mu_ecdfs <- do.call(rbind, lapply(some_ecdfs$mu_tau_ecdf_quantiles, unlist))
        mu_ecdfs_df <- as.data.frame(mu_ecdfs)
        mu_ecdfs_df$param <- rownames(mu_ecdfs)
        mu_ecdfs_df
    }))
mu_ecdfrez_df <- tidyr::gather(mu_ecdfrez_df, k, value, -param)

beta_ecdfrez_df <- do.call(
    rbind,
    lapply(ecdf_files, function(filename){
        some_ecdfs <- readRDS(filename)
        beta_ecdfs <- do.call(rbind, some_ecdfs$beta_ecdf_quantiles)
        beta_ecdfs_df <- as.data.frame(beta_ecdfs)
        beta_ecdfs_df$param <- rownames(beta_ecdfs)
        beta_ecdfs_df
    }))
beta_ecdfrez_df <- tidyr::extract(beta_ecdfrez_df, param, into = c('param_name', 'id'), regex = '(.*)\\.(.*)')


ggplot2::ggplot(mu_ecdfrez_df,
                 ggplot2::aes(x = value)) + 
    ggplot2::geom_histogram(binwidth = 1/3) + 
    ggplot2::facet_grid(param ~ k)

ggplot2::ggplot(
    dplyr::mutate(
        dplyr::arrange(
            dplyr::group_by(mu_ecdfrez_df,
                            param, k),
            value),
        unif_df = punif(seq(min(value), max(value), length.out = n()))),
    ggplot2::aes(x = unif_df, y = value)) +
    ggplot2::geom_abline(intercept = 0, slope = 1, color = 'red') +
    ggplot2::geom_step()+
    ggplot2::coord_cartesian(xlim = c(0,1), ylim = c(0,1)) + 
    ggplot2::facet_grid(param ~ k)

knitr::kable(
    dplyr::summarize(dplyr::group_by(mu_ecdfrez_df, param),
                     p_in_outer_5 = mean(value > .975 | value < .025),
                     p_in_inner_95 = mean(value <= .975 & value >= .025),
                     N = n(),
                     pse = (p_in_outer_5*p_in_inner_95/N)^.5,
                     p_in_outer_5_l = p_in_outer_5 - 2*pse,
                     p_in_outer_5_u = p_in_outer_5 + 2*pse,
                     ks.D = ks.test(unique(value), punif)$statistic,
                     ks.p = ks.test(unique(value), punif)$p.value),
    digits = 3)

ggplot2::ggplot(beta_ecdfrez_df,
                 ggplot2::aes(x = ecdf_quantile)) + 
    ggplot2::geom_density(bw = .08) + 
    ggplot2::geom_vline(xintercept = c(.025, .975)) + 
    ggplot2::facet_grid(param_name ~ k)

ggplot2::ggplot(
    dplyr::mutate(
        dplyr::arrange(
            dplyr::group_by(beta_ecdfrez_df,
                            param_name, k),
            ecdf_quantile),
        unif_df = punif(seq(min(ecdf_quantile), max(ecdf_quantile), length.out = n()))),
    ggplot2::aes(x = unif_df, y = ecdf_quantile)) +
    ggplot2::geom_abline(intercept = 0, slope = 1, color = 'red') +
    ggplot2::geom_step()+
    ggplot2::coord_cartesian(xlim = c(0,1), ylim = c(0,1)) + 
    ggplot2::facet_grid(param_name ~ k)

knitr::kable(
    dplyr::summarize(dplyr::group_by(beta_ecdfrez_df, param_name, k),
                     p_in_outer_5 = mean(ecdf_quantile > .975 | ecdf_quantile< .025),
                     p_in_inner_95 = mean(ecdf_quantile <= .975 & ecdf_quantile >= .025),
                     N = n(),
                     pse = (p_in_outer_5*p_in_inner_95/N)^.5,
                     p_in_outer_5_l = p_in_outer_5 - 2*pse,
                     p_in_outer_5_u = p_in_outer_5 + 2*pse,
                     ks.D = ks.test(unique(ecdf_quantile), punif)$statistic,
                     ks.p = ks.test(unique(ecdf_quantile), punif)$p.value),
    digits = 3)



```


# Conclusion

The model is able to recover data generating parameters from simulated data and is safe to use in interpretting the data provided by the study participants.

# References


```{r echo = F, eval = T}
save.image(file = file.path(save_out_dir, 'test-simulated-data.rda'))
```
